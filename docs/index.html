<!DOCTYPE html>
<html>

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FRE: A Fast Method For Anomaly Detection And Segmentation</title>
  <link rel="stylesheet" href="main.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
  <article>
    <header>
      <nav>
        <a href="https://github.com/IntelLabs/dfm/tree/ICIP2022">ICIP 2022 Code</a> |
        <a href="https://github.com/IntelLabs/dfm/tree/main">BMVC 2023 Code</a>
      </nav>
      <h1>FRE: A Fast Method For Anomaly Detection And Segmentation</h1>
      <p class="centered">Ibrahima J. Ndiour, Nilesh A. Ahuja, Utku Genc and Omesh Tickoo<br />Intel Labs</p>
    </header>

    <section class="main">
      <h2>Introduction</h2>
      <p>We present a fast and principled approach to address the challenge of visual anomaly detection and segmentation. Our method operates under the assumption of having access solely to anomaly-free training data while aiming to identify anomalies of an arbitrary nature on test data. We build upon prior research and present a generalized approach that utilizes a shallow linear autoencoder to perform out-of-distribution detection on the intermediate features generated by a pre-trained deep neural network. More specifically, we compute the feature reconstruction error (FRE) and establish it as principled measure of uncertainty. We rigorously connect our technique to the theory of linear auto-associative networks to provide a solid theoretical foundation and to offer multiple practical implementation strategies. Furthermore, extending the FRE concept to convolutional layers, we derive FRE maps that provide precise pixel-level spatial localization of the anomalies within images, effectively achieving segmentation. Extensive experimentation demonstrates that our method outperforms the current state of the art. It excels in terms of speed, robustness, and remarkable insensitivity to parameterization. We make our code available on <a href="https://github.com/intellabs/dfm">github</a>.</p>
    </section>

    <section class="main">
      <h2>Proposed Approach
      </h2>

      <div class="figure-container">

        <figure>
          <img src="fre_pipeline.png" alt="Pipeline" width="500px">
          <figcaption>Block diagram of our proposed approach.
          </figcaption>
        </figure>

      </div>

      <p>At training: we pass the training data through the backbone network for a single forward pass and consider the
        intermediate (training) features at a given layer k. Subsequently, we train a (tied) shallow linear autoencoder
        with such features.</p>
      <p>During inference: the autoencoder is applied to a test feature to obtain the reduced-dimension embedding, and
        its reconstruction back into the original (feature) space. The feature reconstruction error (FRE) is then
        calculated and used as an uncertainty score:
      </p>
      <p>
        $$\begin{equation}
        FRE(\mathbf{u}, \mathcal{T}) = \mathbf{e} \triangleq \mathbf{u}-\mathbf{\hat{u}} = \mathbf{u}-(\mathcal{T}^{inv}
        \circ \mathcal{T})\mathbf{u}.
        \end{equation}$$
      </p>

      <p>To derive the segmentation map, we perform channel-wise averaging on the FRE (re-arranged as a tensor) in order
        to accumulate the FRE errors along the channel dimension. This produces a single-channel FRE anomaly map M,
        where higher intensity regions correspond to anomalies.
      </p>

      <p>The following detection score is highly effective at discriminating between normal and anomalous samples:
      </p>

      <p>
        $$\begin{equation*}
        \mathbf{M}_k(i,j) = \frac{1}{C_k}\sum_{c=1}^{C_k} \mathbf{e}(c,i,j)
        %, i\in {1, 2, \dots, W_k}, i\in {1, 2, \dots, W_k}
        \end{equation*}$$
      </p>
    </section>


    <section class="main">
      <h2>Results
      </h2>

      <h3>Detection results</h3>

      <div class="figure-container">
        <figure>
          <img src="det_table1.png" alt="Detection table 1">
          <figcaption>MVTec dataset (AUROC metric ↑).</figcaption>
        </figure>
      </div>

      <div class="figure-container">
        <figure>
          <img src="det_table2.png" alt="Detection table 2">
          <figcaption>Magnetic Tile dataset (AUROC metric ↑). </figcaption>
        </figure>
      </div>

      <div class="figure-container">
        <figure>
          <img src="det_table3.png" alt="Detection table 3">
          <figcaption>MVTec dataset for FRE across backbones (AUROC metric ↑). </figcaption>
        </figure>
      </div>

      <h3>Segmentation results</h3>

      <div class="figure-container">
        <figure>
          <img src="seg_table1.png" alt="Segmentation table 1" width="500px">
          <figcaption>Pixel-AUROC and PRO metrics on MVTec dataset.
          </figcaption>
        </figure>
      </div>

      <div class="figure-container">
        <figure>
          <img src="results.png" alt="Segmentation results" width="500px">
          <figcaption>From left to right, each set of four images comprises: original image, ground truth segmentation mask, anomaly heatmap using FRE (our method) from a single layer, anomaly heatmap using FRE from three layers.</figcaption>
        </figure>
      </div>

      <div class="figure-container">
        <figure>
          <img src="seg_table2.png" alt="Segmentation table 2" width="500px">
          <figcaption>Pixel-wise AUROC and PRO metrics on MVTec for FRE across backbones.
          </figcaption>
        </figure>
      </div>

    </section>

    <footer>
      <p class="centered">November 2023</p>
    </footer>
  </article>
</body>

</html>


<!-- <img src = "poster.svg" alt="BMVC poster" width="600px"/> -->