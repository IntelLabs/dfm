<!DOCTYPE html>
<html>

<head>
  <title>FRE: A Fast Method For Anomaly Detection And Segmentation</title>
  <link rel="stylesheet" href="main.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>
  <article>
    <header>
      <h1>FRE: A Fast Method For Anomaly Detection And Segmentation</h1>
      <p>Ibrahima J. Ndiour, Nilesh A. Ahuja, Utku Genc and Omesh Tickoo<br />Intel Labs</p>
    </header>
    
    <section class="main">
      <h2>Abstract</h2>
      <p>This work proposes a fast and principled method for unsupervised anomaly detection and segmentation. Our method
        operates under the assumption of having access solely to anomaly-free training data while aiming to identify
        anomalies of an arbitrary nature on test data.
        We make our code available on <a href="https://intellabs.github.io/dfm">github</a>.
      </p>
    </section>

    <section class="main">
      <h2>Contributions</h2>
      <p>The principal contributions of the work include:
        <ul>
          <li>a generalized approach that utilizes a shallow linear autoencoder as a principled out-of-distribution detection method operating in the feature space produced by a pre-trained DNN.</li>
          <li>a solid theoretical foundation for the method establishing the feature reconstruction error (FRE) as a principled measure of uncertainty.</li>
          <li>simultaneous solving of image-level anomaly detection and pixel-level anomaly segmentation.</li>
          <li>multiple implementation strategies addressing concerns related to memory, computational complexity, and dataset size. </li>
          <li>extensive experimentation showing state-of-the-art quality, as well as speed, robustness and insensitivity to parameterization.</li>
        </ul>        
      </p>
    </section>

    <section class="main">
      <h2>Preliminaries: linear auto-associative networks
      </h2>

      <div class="figure-container">
      <figure>
        <img src="aan.png" alt="AAN" width="150px">
        <figcaption>Auto-associative network.</figcaption>
      </figure>

      <figure>
        <img src="subspace.png" alt="Subspace" width="150px">
        <figcaption>FRE visualization as distance to the principal subspace.</figcaption>
      </figure>

    </div>
      <p>
        <ul>
          <li>The auto-associative network performs orthogonal projection onto the subspace spanned by the first principal eigenvectors of a covariance matrix associated with the training patterns. </li>
          <li>How does a neural network perform when exposed to a pattern never seen previously?</li>
          <li>In the auto-associative case, a precise quantitative answer can be given: the distortion on a new pattern is exactly given by its distance to the subspace generated by the first p eigenvectors of the data covariance matrix.</li>      
        </ul>     
        
      </p>
    </section>

    <section class="main">
      <h2>Proposed Approach
      </h2>

      <div class="figure-container">

      <figure>
        <img src="fre_pipeline.png" alt="Pipeline" width="400px">
        <figcaption>Block diagram of our proposed approach.
        </figcaption>
      </figure>

      </div>

      <p>
        <ul>
          <li>The auto-associative network performs orthogonal projection onto the subspace spanned by the first principal eigenvectors of a covariance matrix associated with the training patterns. </li>
          <li>How does a neural network perform when exposed to a pattern never seen previously?</li>
          <li>In the auto-associative case, a precise quantitative answer can be given: the distortion on a new pattern is exactly given by its distance to the subspace generated by the first p eigenvectors of the data covariance matrix.</li>      
        </ul>     
        
      </p>
    </section>
    
    <footer>
      <p>November 2023</p>
    </footer>
  </article>
</body>

</html>


<!-- <img src = "poster.svg" alt="BMVC poster" width="600px"/> -->